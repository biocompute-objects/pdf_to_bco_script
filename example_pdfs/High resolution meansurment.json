{
    "object_id": "",
    "etag": "",
    "spec_version": "https://w3id.org/ieee/ieee-2791-schema/2791object.json",
    "provenance_domain": {
        "name": "High resolution measurement of DUF1220 domain copy number from whole genome sequence data",
        "version": "2.0",
        "license": "http://creativecommons.org/licenses/by/4.0/",
        "created": "2024-08-09T13:55:00.758511Z",
        "modified": "2024-08-09T13:55:00.758511Z",
        "contributors": [
            {
                "name": "Aditya Lahiri",
                "email": "adityalahiri06@gmail.com",
                "affiliation": "George Washington University",
                "contribution": [
                    "curatedBy"
                ]
            }
        ]
    },
    "usability_domain": [
        "Background: DUF1220 protein domains found primarily in Neuroblastoma BreakPoint Family (NBPF) genes show the greatest human lineage-specific increase in copy number of any coding region in the genome",
        "There are 302 haploid copies of DUF1220 in hg38 (~160 of which are human-specific) and the majority of these can be divided into 6 different subtypes (referred to as clades)",
        "Copy number changes of specific DUF1220 clades have been associated in a dose-dependent manner with brain size variation (both evolutionarily and within the human population), cognitive aptitude, autism severity, and schizophrenia severity",
        "However, no published methods can directly measure copies of DUF1220 with high accuracy and no method can distinguish between domains within a clade",
        "Results: Here we describe a novel method for measuring copies of DUF1220 domains and the NBPF genes in which they are found from whole genome sequence data",
        "We have characterized the effect that various sequencing and alignment parameters and strategies have on the accuracy and precision of the method and defined the parameters that lead to optimal DUF1220 copy number measurement and resolution",
        "We show that copy number estimates obtained using our read depth approach are highly correlated with those generated by ddPCR for three representative DUF1220 clades",
        "By simulation, we demonstrate that our method provides sufficient resolution to analyze DUF1220 copy number variation at three levels: (1) DUF1220 clade copy number within individual genes and groups of genes (gene-specific clade groups) (2) genome wide DUF1220 clade copies and (3) gene copy number for DUF1220-encoding genes",
        "Conclusions: To our knowledge, this is the first method to accurately measure copies of all six DUF1220 clades and the first method to provide gene specific resolution of these clades",
        "This allows one to discriminate among the ~300 haploid human DUF1220 copies to an extent not possible with any other method",
        "The result is a greatly enhanced capability to analyze the role that these sequences play in human variation and disease."
    ],
    "description_domain": {
        "keywords": [
            ""
        ],
        "pipeline_steps": [
            {
                "step_number": 1,
                "name": "Analysis of sequence data from the 1000 genomes project",
                "description": "Analysis of sequence data from the 1000 genomes project\nRaw sequence data were obtained from the 1000 Genomes Project [34] via ftp download from EBI ftp://ftp.sra.ebi.ac.uk/vol1/fastq . The full list of sequence data was obtained from ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/. Approximately 25 individuals were randomly chosen from each of the CEU, YRI, CHB, JPT, MXL, CLM, PUR, ASW, LWK, CHS, TSI, IBS, FIN, and GBR populations for a total of 324 individuals. Individuals from the CEU, YRI, CHB, and JPT populations were selected to match with those reported previously [21]. The data were obtained from the Illumina 2000 with 100 bp paired-end reads, with an average of 139 million reads and 15\u00d7 coverage per genome. The reads were filtered and trimmed to remove low quality bases (Phred score < 10) from the 3\u2032 ends of the read using Cutadapt (version 1.31) [35] (cutadapt \u2013a XXX \u2013A XXX \u2013q 10 \u2013minimum-length 80 \u2013trim-n). Reads trimmed shorter than 80 bases were removed (on average 18.5 million reads per sample). Samples with less than 10\u00d7 coverage were removed from the analysis. Coverage was calculated by multiplying the number of filtered reads by the insert size and dividing by the number of bases in the human genome reference. The sequence data were analyzed following the \u2018best\u2019 align strategy as described above and outlined in Fig. 9. For copy number estimation, the genomic coordinates spanning the short and long exons of each DUF1220 domain were combined. Where the domains were more than 1 kb apart, the boundaries of the domains were extended up to 250 bp to allow the possibility of capturing unique sequence directly adjacent to the domain. Sequence coverage for each region of interest is then normalized by dividing the coverage for every region of interest by the mean coverage of highly conserved regions and multiplying the normalized value by a GC correction factor. To derive GC correction factors, the genome including highlyconserved regions were binned into 1 kb windows and the read depth is plotted against the %GC content. A Loess regression model is fitted to the data to determine the correction factor for each GC bin. The background regions used for normalization and GC correction were derived by merging regions from our simulations that map uniquely to the human genome reference within two mismatches along with regions from the database of Ultra-Conserved Elements (UCE) [36]. Any regions found in the Database of Genomic Variants [37] were subtracted from the background regions.\n\n",
                "versions": "",
                "input_list": {
                    "filename": "",
                    "access_time": "2024-08-09T13:55:00.804243Z",
                    "uri": "ftp://ftp.sra.ebi.ac.uk/vol1/fastq",
                    "sha1_checksum": ""
                },
                "output_list": {
                    "filename": "",
                    "access_time": "2024-08-09T13:55:00.804243Z",
                    "uri": "",
                    "sha1_checksum": ""
                }
            },
            {
                "step_number": 2,
                "name": "Source code",
                "description": "Source code\nThe source code used to analyze the 1000 Genomes data is available online at https://github.com/dpastling/plethora. And the source code used to carry out the simulations is available at https://github.com/dpastling/DUF1220_simulation. The source code used to annotate DUF1220 domains is available at https://github.com/IleaHeft/DUF1 220annotator.\n\nAll source code used in this study is released under the MIT License and archived on Zenodo at http://doi.org/10.5281/zenodo.840606.\n\n",
                "versions": "",
                "input_list": {
                    "filename": "",
                    "access_time": "2024-08-09T13:55:00.830754Z",
                    "uri": "https://github.com/dpastling/plethora.",
                    "sha1_checksum": ""
                },
                "output_list": {
                    "filename": "",
                    "access_time": "2024-08-09T13:55:00.830754Z",
                    "uri": "",
                    "sha1_checksum": ""
                }
            }
        ]
    },
    "execution_domain": {
        "external_data_endpoints": [],
        "environment_variables": {},
        "scripts": [],
        "software_prerequisites": [
            {
                "filename": "fastq",
                "uri": "ftp://ftp.sra.ebi.ac.uk/vol1/fastq",
                "access_time": "",
                "sha1_checksum": ""
            },
            {
                "filename": ".",
                "uri": "ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/.",
                "access_time": "",
                "sha1_checksum": ""
            },
            {
                "filename": "plethora.",
                "uri": "https://github.com/dpastling/plethora.",
                "access_time": "",
                "sha1_checksum": ""
            },
            {
                "filename": "DUF1220_simulation.",
                "uri": "https://github.com/dpastling/DUF1220_simulation.",
                "access_time": "",
                "sha1_checksum": ""
            },
            {
                "filename": "DUF1",
                "uri": "https://github.com/IleaHeft/DUF1",
                "access_time": "",
                "sha1_checksum": ""
            },
            {
                "filename": "zenodo.840606.",
                "uri": "http://doi.org/10.5281/zenodo.840606.",
                "access_time": "",
                "sha1_checksum": ""
            }
        ]
    },
    "extension_domain": {},
    "error_domain": {},
    "parametric_domain": [],
    "io_domain": {}
}